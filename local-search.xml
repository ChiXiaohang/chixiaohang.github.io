<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>炼丹之深度学习环境配置</title>
    <link href="/2022/02/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    <url>/2022/02/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
    
    <content type="html"><![CDATA[<h2 id="1-安装Nvida驱动以及CUDA"><a href="#1-安装Nvida驱动以及CUDA" class="headerlink" title="1.安装Nvida驱动以及CUDA"></a>1.安装Nvida驱动以及CUDA</h2><p>根据自己电脑显卡型号，在[Nvida官网](<a href="https://www.nvidia.cn/Download/index.aspx?lang=cn">官方驱动 | NVIDIA</a>)安装对应的显卡驱动，安装过程全部Next.</p><p><img src="https://cdn.jsdelivr.net/gh/ChiXiaohang/Image/image-20220212221129544-16464832328741.png" srcset="/img/loading.gif" lazyload alt="Nvida官网"></p><p>安装完成后重启电脑，在命令终端中输入</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">nvidia-smi<br></code></pre></div></td></tr></table></figure><p>结果如下图：</p><p><img src="https://cdn.jsdelivr.net/gh/ChiXiaohang/Image/image-20220306214536493.png" srcset="/img/loading.gif" lazyload alt="image-20220306214536493"></p><p>第一阶段完成！</p><h2 id="2-加载cuDNN加速包"><a href="#2-加载cuDNN加速包" class="headerlink" title="2.加载cuDNN加速包"></a>2.加载cuDNN加速包</h2><ol><li>在<a href="https://developer.nvidia.com/cudnn">官网</a>下载cuDNN深度神经网络的GPU加速库， <strong>注意！</strong>，cuDNN是一个支持包，并不是可执行文件。</li><li>将下载完成</li></ol><h2 id="3-安装Anaconda环境"><a href="#3-安装Anaconda环境" class="headerlink" title="3.安装Anaconda环境"></a>3.安装Anaconda环境</h2><h2 id="4-环境测试"><a href="#4-环境测试" class="headerlink" title="4.环境测试"></a>4.环境测试</h2><p>以下代码为CPU与GPU在张量运算下的速度测试：</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-built_in">print</span>(torch.__version__)        <span class="hljs-comment"># 返回pytorch的版本</span><br><span class="hljs-built_in">print</span>(torch.cuda.is_available())        <span class="hljs-comment"># 当CUDA可用时返回True</span><br><br>a = torch.randn(<span class="hljs-number">10000</span>, <span class="hljs-number">10000</span>)    <span class="hljs-comment"># 返回10000行10000列的张量矩阵</span><br>b = torch.randn(<span class="hljs-number">10000</span>, <span class="hljs-number">5000</span>)     <span class="hljs-comment"># 返回10000行5000列的张量矩阵</span><br><br>t0 = time.time()        <span class="hljs-comment"># 记录时间</span><br>c = torch.matmul(a, b)      <span class="hljs-comment"># 矩阵乘法运算</span><br>t1 = time.time()        <span class="hljs-comment"># 记录时间</span><br><span class="hljs-built_in">print</span>(a.device, t1 - t0)<br><br>device = torch.device(<span class="hljs-string">&#x27;cuda&#x27;</span>)       <span class="hljs-comment"># 用GPU来运行</span><br>a = a.to(device)<br>b = b.to(device)<br><br><span class="hljs-comment"># 初次调用GPU，需要数据传送，因此比较慢</span><br>t0 = time.time()<br>c = torch.matmul(a, b)<br>t2 = time.time()<br><span class="hljs-comment"># 这才是GPU处理数据的真实运行时间，当数据量越大，GPU的优势越明显</span><br>t0 = time.time()<br>c = torch.matmul(a, b)<br>t2 = time.time()<br><span class="hljs-built_in">print</span>(a.device, t2 - t0)<br></code></pre></div></td></tr></table></figure><p>输出：</p><p><code>cpu 7.230173587799072   </code></p><p><code>cuda:0 0.0009875297546386719</code></p><p>同一张量运算，GPU是CPU处理速度的成百上千倍。在深度学习网络中，模型规模越庞大，网络层数越深，GPU的速度优势就愈发明显。</p><p>至此，GPU配置工作完成，可以开启愉快的炼丹之旅了！</p>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>配置</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
